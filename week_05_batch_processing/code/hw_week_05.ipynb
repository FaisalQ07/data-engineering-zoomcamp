{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a88833-f88a-4e50-9088-40a23dd82bb7",
   "metadata": {},
   "source": [
    "## Question 1. Install Spark and PySpark\n",
    "1. Install Spark\n",
    "2. Run PySpark\r",
    "3. \n",
    "Create a local spark sessio\n",
    "4. Execute spark.versiono5. What's the output?n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52de6488-c8f1-437a-9d77-0ff663130cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import concat_ws, year, month, dayofmonth, unix_timestamp\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba964e-41a0-4d2b-a643-ac01323c8672",
   "metadata": {},
   "source": [
    "## Question 2. FHV October 2019 partition size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b29be3-334a-4bd2-a638-234ecc2a4a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "input_path = f'data/raw/fhv/2019/10/'\n",
    "output_path = f'data/pq/fhv/2019/10/'\n",
    "\n",
    "df_fhv = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .csv(input_path)\n",
    ")\n",
    "\n",
    "(\n",
    "    df_fhv\n",
    "    .repartition(6) \\\n",
    "    .write.parquet(output_path, mode='overwrite')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c42cb68-9393-4106-ae89-b96a43332421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 39M\n",
      "-rw-r--r-- 1 faisal faisal    0 Feb 25 19:55 _SUCCESS\n",
      "-rw-r--r-- 1 faisal faisal 6.4M Feb 25 19:55 part-00000-43bf6a3e-f177-451a-a402-715f8bf27ab3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 faisal faisal 6.4M Feb 25 19:55 part-00001-43bf6a3e-f177-451a-a402-715f8bf27ab3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 faisal faisal 6.4M Feb 25 19:55 part-00002-43bf6a3e-f177-451a-a402-715f8bf27ab3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 faisal faisal 6.4M Feb 25 19:55 part-00003-43bf6a3e-f177-451a-a402-715f8bf27ab3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 faisal faisal 6.4M Feb 25 19:55 part-00004-43bf6a3e-f177-451a-a402-715f8bf27ab3-c000.snappy.parquet\n",
      "-rw-r--r-- 1 faisal faisal 6.4M Feb 25 19:55 part-00005-43bf6a3e-f177-451a-a402-715f8bf27ab3-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./data/pq/fhv/2019/10/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5624c-5d09-4cb0-9d04-fee9b0685746",
   "metadata": {},
   "source": [
    "## Question 3. Count records on 15th of October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb781726-1814-4e74-8f28-9892db648734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv_parquet = (\n",
    "    spark.read\n",
    "    .parquet('data/pq/fhv/2019/10/')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f2073c2-bf0f-4ab1-b615-bd1a4a77c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv_parquet = (\n",
    "    df_fhv_parquet\n",
    "    .withColumn('pickup_date',\n",
    "                concat_ws('-', \n",
    "                          year(df_fhv_parquet.pickup_datetime), \n",
    "                          month(df_fhv_parquet.pickup_datetime),\n",
    "                          dayofmonth(df_fhv_parquet.pickup_datetime)\n",
    "                         )\n",
    "               )\n",
    ")\n",
    "\n",
    "df_fhv_parquet_count = (\n",
    "    df_fhv_parquet\n",
    "    .filter(df_fhv_parquet.pickup_date == '2019-10-15')\n",
    "    .groupBy('pickup_date')\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9116923e-54b0-4b55-99c9-b462e587bc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|pickup_date|count|\n",
      "+-----------+-----+\n",
      "| 2019-10-15|62610|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fhv_parquet_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956e5fdf-ef42-4a13-9b3c-c19c2075a74c",
   "metadata": {},
   "source": [
    "## Question 4. The longest trip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5e773f8-5cb9-4144-8698-0993fa2d92b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|pickup_date|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   NULL|                  NULL|  2019-10-1|\n",
      "|              B02429|2019-10-21 04:15:47|2019-10-21 04:36:04|         264|         264|   NULL|                B02429| 2019-10-21|\n",
      "|              B01482|2019-10-19 12:00:00|2019-10-19 12:20:00|         264|         264|   NULL|                B01482| 2019-10-19|\n",
      "|              B03015|2019-10-11 14:28:00|2019-10-11 14:32:44|         264|         216|   NULL|                B03015| 2019-10-11|\n",
      "|              B01529|2019-10-21 18:00:26|2019-10-21 18:07:21|         264|          80|   NULL|                B01529| 2019-10-21|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhv_parquet.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df39aed2-a373-438c-84cc-685ca38182a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference in seconds between dropOff_datetime and pickup_datetime\n",
    "df_with_diff = (\n",
    "    df_fhv_parquet\n",
    "    .withColumn(\"trip_duration_seconds\", \n",
    "                F.unix_timestamp(F.col(\"dropOff_datetime\")) - F.unix_timestamp(F.col(\"pickup_datetime\"))\n",
    "               )\n",
    ")\n",
    "\n",
    "# Convert the difference from seconds to hours\n",
    "df_with_diff = (\n",
    "    df_with_diff\n",
    "    .withColumn(\"trip_duration_hours\", F.col(\"trip_duration_seconds\") / 3600)   \n",
    ")\n",
    "\n",
    "# Find the maximum trip duration in hours\n",
    "df_max_trip_duration_hours = (\n",
    "    df_with_diff\n",
    "    .groupBy('pickup_date')\n",
    "    .agg(F.max(\"trip_duration_hours\").alias('max_trip_duration_hours'))\n",
    "    .orderBy('max_trip_duration_hours', ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d30b9217-47cb-472e-82a2-e224b53c4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+\n",
      "|pickup_date|max_trip_duration_hours|\n",
      "+-----------+-----------------------+\n",
      "| 2019-10-11|               631152.5|\n",
      "| 2019-10-28|               631152.5|\n",
      "| 2019-10-31|      87672.44083333333|\n",
      "|  2019-10-1|      70128.02805555555|\n",
      "| 2019-10-17|                 8794.0|\n",
      "+-----------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_max_trip_duration_hours.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09766cdb-010d-4f17-8d11-6ff277af8951",
   "metadata": {},
   "source": [
    "## Question 5. Spark UI port \n",
    "\n",
    "Answer: 4040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb29e4b-d06a-47bd-b497-187875779d54",
   "metadata": {},
   "source": [
    "## Question 6. Least frequent pickup location zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87a7bf25-1c85-4fd7-b173-05e9cb788197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", True)\n",
    "    .csv('data/lookup/zone/taxi_zone_lookup.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70483d99-bd14-4dba-9923-cc985004d5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show(5)\n",
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37ff689d-e306-481a-97a5-85b349facdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = (\n",
    "    df_fhv_parquet\n",
    "    .join(df_zones\n",
    "          , df_fhv_parquet.PUlocationID == df_zones.LocationID\n",
    "          , how = 'left'\n",
    "         )\n",
    "    .groupBy('Zone')\n",
    "    .agg(F.count('*').alias('Zone_Frequency'))\n",
    "    .orderBy('Zone_Frequency')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d800a7c-0aef-4ac1-b3a3-17f04cc76608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|                Zone|Zone_Frequency|\n",
      "+--------------------+--------------+\n",
      "|         Jamaica Bay|             1|\n",
      "|Governor's Island...|             2|\n",
      "| Green-Wood Cemetery|             5|\n",
      "|       Broad Channel|             8|\n",
      "|     Highbridge Park|            14|\n",
      "+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be40d4e3-f43b-4c29-b009-29378d7be6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5bb6cb-a56d-48cb-908f-47523257ec6a",
   "metadata": {},
   "source": [
    "## Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
